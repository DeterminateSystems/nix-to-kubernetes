name: Build Docker image using Nix and deploy to Kubernetes

on:
  pull_request:
  push:
    branches:
      - main

jobs:
  # Build the Docker image using Nix
  build:
    # We need to use this machine type (x86_64-linux in Nix) or else the
    # Nix-built Docker image won't run properly
    runs-on: ubuntu-latest
    environment: build
    # This environment includes a number of secrets:
    # CACHIX_CACHE is the name of the Cachix cache
    # CACHIX_AUTH_TOKEN is the auth token required to access CACHIX_CACHE
    outputs:
      image: ${{ steps.set-image.outputs.image }}
    steps:
      - name: git checkout
        uses: actions/checkout@v3

      # Install Nix and set up a local Nix store under /nix/store
      - name: Install Nix
        uses: cachix/install-nix-action@v18
        with:
          extra_nix_config: |
            access-tokens = github.com=${{ secrets.GITHUB_TOKEN }}
            binary-caches = https://cache.nixos.org https://${{ secrets.CACHIX_CACHE }}.cachix.org

      # Use Cachix to speed up builds
      - name: Set up Cachix
        uses: cachix/cachix-action@v11
        with:
          name: ${{ secrets.CACHIX_CACHE }}
          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}

      # Note that we use Nix to build the Docker image and NOT the Docker CLI
      - name: Build Docker image for horoscope service using Nix
        run: nix build ".#docker"

      # All Nix build artifacts are cached in Cachix, which should speed up
      # future builds.
      - name: Cache build artifacts
        run: |
          nix flake archive --json \
            | jq -r '.path,(.inputs|to_entries[].value.path)' \
            | cachix push "${{ secrets.CACHIX_CACHE }}"

      # We need to log into the GitHub Container Registry in order to push images
      - name: Docker login
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # No tag is provided in the Nix build configuration for our Docker image.
      # When no tag is provided, Nix generates one for you based on the contents
      # of the build inputs. This ensures that the image tag changes any time
      # any aspect of the build changes (even one character in one file). In
      # this CI step, the image is loaded, the image tag is inferred from the
      # build output, and then that tag is saved to the CI environment under the
      # IMAGE_TAG environment variable (used later during deployment).
      - name: Load and push image to GHCR
        run: |
          export IMAGE_TAG=$(docker load < result | grep -Po 'Loaded image: \K.*')
          echo "Pushing image ${IMAGE_TAG} to GHCR"
          echo "IMAGE_TAG=${IMAGE_TAG}" >> $GITHUB_ENV
          docker push "${IMAGE_TAG}"

      # Set the image name "globally" (across runners) so that the `deploy` job
      # can use it.
      - id: set-image
        name: Set image name
        run: |
          echo "::set-output name=image::${{ env.IMAGE_TAG }}"

  # Deploy the newly built image to Kubernetes
  deploy:
    needs: build
    runs-on: ubuntu-latest # x86_64-linux
    environment: deploy
    # This environment includes a number of secrets:
    # K8S_CONTEXT is the name of the Kubernetes context (generated by DigitalOcean)
    # K8S_CLUSTER_NAME is the name of the Kubernetes cluster (defined by Terraform variable)
    # DIGITALOCEAN_TOKEN is an API token to access DigitalOcean
    steps:
      - name: git checkout
        uses: actions/checkout@v3

      # Install Nix and set up a local Nix store under /nix/store.
      - name: Install Nix
        uses: cachix/install-nix-action@v18
        with:
          extra_nix_config: |
            access-tokens = github.com=${{ secrets.GITHUB_TOKEN }}
            binary-caches = https://cache.nixos.org https://${{ secrets.CACHIX_CACHE }}.cachix.org

      # Use Cachix to speed up builds
      - name: Set up Cachix
        uses: cachix/cachix-action@v11
        with:
          name: ${{ secrets.CACHIX_CACHE }}
          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}

      # Enable admin access to the DigitalOcean Kubernetes service
      - name: Authenticate with DigitalOcean
        env:
          DO_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
        run: |
          nix develop --command \
            doctl auth init --access-token "${DO_TOKEN}"

      # Import the Kubernetes configuration for our cluster into the CI
      # environment (so that kubectl knows how to talk to the cluster)
      - name: Import kubeconfig
        env:
          K8S_CLUSTER_NAME: ${{ secrets.K8S_CLUSTER_NAME }}
        run: |
          nix develop --command \
            doctl kubernetes cluster kubeconfig save "${K8S_CLUSTER_NAME}"

      # Use the handy kubectx tool to enable kubectl to talk to the cluster
      - name: Set Kubernetes context
        env:
          K8S_CONTEXT: ${{ secrets.K8S_CONTEXT }}
        run: |
          nix develop --command \
            kubectx "${K8S_CONTEXT}"

      # "Ping" the cluster by listing available nodes
      - name: List nodes (to verify that kubectl can interact with the cluster)
        run: |
          nix develop --command \
            kubectl get nodes

      # Authorize the Kubernetes cluster to pull images from GitHub Container
      # Registry by creating a special Kubernetes Secret of type
      # `docker-registry`.
      - name: Enable GHCR in Kubernetes
        env:
          GHCR_USERNAME: ${{ github.repository_owner }}
          GHCR_PASSWORD: ${{ secrets.GITHUB_TOKEN }}
        run: |
          nix develop --command \
            kubectl delete secret ghcr-secret --ignore-not-found

          nix develop --command \
            kubectl create secret docker-registry ghcr-secret \
              --docker-server=https://ghcr.io \
              --docker-username "${GHCR_USERNAME}" \
              --docker-password "${GHCR_PASSWORD}"

      # Apply our Kubernetes Deployment's configuration
      - name: kubectl apply
        run: |
          nix develop --command \
            kubectl apply \
              --filename ./kubernetes/deployment.yaml

      # Initially, the Deployment runs the `registry.k8s.io/echoserver:1.4`
      # image, which is meant to be replaced by our horoscope image. This step
      # replaces the `echoserver` image with the freshly built service.
      - name: Update image
        env:
          IMAGE_TAG: ${{ needs.build.outputs.image }}
        run: |
          nix develop --command \
            kubectl set image deployment.apps/horoscope-deployment \
              horoscope="${IMAGE_TAG}"

      # Kubernetes now knows which image to pull for our Deployment, but a
      # restart is necessary to actually pull/run the image.
      - name: Restart the Deployment
        run: |
          nix develop --command \
            kubectl rollout restart deployment.apps/horoscope-deployment
